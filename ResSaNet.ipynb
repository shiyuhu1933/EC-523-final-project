{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResSaNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMzHHZXcVX+q3GIejzc3z88",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiyuhu1933/EC-523-final-project/blob/main/ResSaNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kmteXxh3XFTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59d653e-675e-4455-abb9-ac25e59a1620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATASET_GOOGLE_DRIVE_PATH = '/content/gdrive/MyDrive/Deep_Learning /data_hdf5_random_with_aug'\n",
        "\n",
        "\n",
        "def get_file_name(files_list):\n",
        "  with open(files_list) as f:\n",
        "    return [line.rstrip()[:] for line in f]\n",
        "\n",
        "class FaceMaskData(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, mode, config, transform=None):\n",
        "\n",
        "    self.data_dir = DATASET_GOOGLE_DRIVE_PATH\n",
        "    self.transform = transform\n",
        "\n",
        "    if mode == 'train':\n",
        "      self.files = get_file_name(os.path.join(self.data_dir, 'train_files.txt'))\n",
        "    else:\n",
        "      self.files = get_file_name(os.path.join(self.data_dir, 'test_files.txt'))\n",
        "\n",
        "    image = []\n",
        "    label = []\n",
        "\n",
        "    for dataset in self.files:\n",
        "      path = os.path.join(self.data_dir, dataset)\n",
        "      self.file = h5py.File(path, 'r')\n",
        "      self.total_num_imgs, self.H, self.W, self.C = self.file['image'].shape\n",
        "      image.append(self.file['image'][:])\n",
        "      label.append(self.file['labels'][:])\n",
        "\n",
        "    self.image= np.vstack(image)\n",
        "    self.label = np.vstack(label)\n",
        "\n",
        "    self.num_images = len(self.image) \n",
        "    self.num_classes = len(np.unique(self.label))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Return one image and its corresponding attribute label.\"\"\"\n",
        "    image = self.image[index]\n",
        "    label = self.label[index]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    return image, torch.FloatTensor(label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.num_images\n",
        "      \n",
        "  def get_num_class(self):\n",
        "    return self.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_configuration(repeat_num, batch_size):\n",
        "    config = {}\n",
        "\n",
        "    config['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    config['batch_size'] = batch_size\n",
        "    config['num_workers'] = 1\n",
        "    config['repeat_num'] = repeat_num\n",
        "    config['lr'] = 0.0001\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def image_to_rgb(images):\n",
        "  imgs = []\n",
        "  for i in range(len(images)):\n",
        "    image_r = torch.unsqueeze(images[i,:,:,0], 0)\n",
        "    image_g = torch.unsqueeze(images[i,:,:,1], 0)\n",
        "    image_b = torch.unsqueeze(images[i,:,:,2], 0)\n",
        "    image_split_rgb = torch.cat((image_r, image_g, image_b), 0)\n",
        "    image_split_rgb = torch.unsqueeze(image_split_rgb, 0)\n",
        "    imgs.append(image_split_rgb)\n",
        "  return torch.cat(imgs)\n",
        "\n",
        "\n",
        "def print_network(model, name):\n",
        "  \"\"\"Print out the network information.\"\"\"\n",
        "  num_params = 0\n",
        "  print(\"\\n\")\n",
        "  print(\"model name\", name)\n",
        "  print(model)\n",
        "  num_params = sum([par.numel() for par in model.parameters()])\n",
        "  print(\"The number of parameters: {}\".format(num_params))\n",
        "\n",
        "def save_model(model, step):\n",
        "  save_model_path = \"/content/gdrive/MyDrive/Deep Learning /models\"\n",
        "  model_path = os.path.join(save_model_path, 'model-{}.ckpt'.format(step))\n",
        "  torch.save(model, model_path)\n",
        "  print('Saved model checkpoints into {}...'.format(save_model_path))\n",
        "\n",
        "def load_model(iters):\n",
        "  path = \"/content/gdrive/MyDrive/Deep Learning /models\"\n",
        "  model_path = os.path.join(path, 'model-{}.ckpt'.format(iters))\n",
        "  model = torch.load(model_path)\n",
        "  return model"
      ],
      "metadata": {
        "id": "2RDml3ilR8xl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "config = get_configuration(repeat_num=10000, batch_size=16)\n",
        "dataset = FaceMaskData('train', config)\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                              batch_size=config['batch_size'],\n",
        "                              shuffle=True, \n",
        "                              num_workers=config['num_workers'])\n",
        "num_classes = dataset.get_num_class()"
      ],
      "metadata": {
        "id": "KVDVmtvLR-xC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class IBSA_Block(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out, stride=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dim_in, self.dim_out = dim_in, dim_out\n",
        "    self.bn1 = nn.BatchNorm2d(dim_in, affine=True, track_running_stats=True)\n",
        "    self.bn2 = nn.BatchNorm2d(dim_out, affine=True, track_running_stats=True)\n",
        "    self.conv = nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=stride)\n",
        "    self.mhsa = nn.MultiheadAttention(dim_in,num_heads=512)\n",
        "    self.prelu = nn.PReLU()\n",
        "  \n",
        "  def forward(self, input):\n",
        "    identity = input\n",
        "\n",
        "    output = self.bn1(input)\n",
        "    output = self.conv(output)\n",
        "    output = self.bn2(output)\n",
        "    output = self.prelu(output)\n",
        "    output = self.mhsa(output)\n",
        "    output = self.bn2(output)\n",
        "\n",
        "    output += identity\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "szB9ZC1uZnpW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def conv_bn_act(in_, out_, kernel_size,\n",
        "                stride=1, groups=1, bias=True,\n",
        "                eps=1e-3, momentum=0.01):\n",
        "    return nn.Sequential(\n",
        "        SamePadConv2d(in_, out_, kernel_size, stride, groups=groups, bias=bias),\n",
        "        nn.BatchNorm2d(out_, eps, momentum),\n",
        "        Swish()\n",
        "    )\n",
        "\n",
        "\n",
        "class SamePadConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True, padding_mode=\"zeros\"):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias, padding_mode)\n",
        "\n",
        "    def get_pad_odd(self, in_, weight, stride, dilation):\n",
        "        effective_filter_size_rows = (weight - 1) * dilation + 1\n",
        "        out_rows = (in_ + stride - 1) // stride\n",
        "        padding_needed = max(0, (out_rows - 1) * stride + effective_filter_size_rows - in_)\n",
        "        padding_rows = max(0, (out_rows - 1) * stride + (weight - 1) * dilation + 1 - in_)\n",
        "        rows_odd = (padding_rows % 2 != 0)\n",
        "        return padding_rows, rows_odd\n",
        "\n",
        "    def forward(self, x):\n",
        "        padding_rows, rows_odd = self.get_pad_odd(x.shape[2], self.weight.shape[2], self.stride[0], self.dilation[0])\n",
        "        padding_cols, cols_odd = self.get_pad_odd(x.shape[3], self.weight.shape[3], self.stride[1], self.dilation[1])\n",
        "\n",
        "        if rows_odd or cols_odd:\n",
        "            x = F.pad(x, [0, int(cols_odd), 0, int(rows_odd)])\n",
        "\n",
        "        return F.conv2d(x, self.weight, self.bias, self.stride,\n",
        "                        padding=(padding_rows // 2, padding_cols // 2),\n",
        "                        dilation=self.dilation, groups=self.groups)\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, in_, squeeze_ch):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_, squeeze_ch, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            Swish(),\n",
        "            nn.Conv2d(squeeze_ch, in_, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.se(x))\n",
        "\n",
        "\n",
        "class DropConnect(nn.Module):\n",
        "    def __init__(self, ratio):\n",
        "        super().__init__()\n",
        "        self.ratio = 1.0 - ratio\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "\n",
        "        random_tensor = self.ratio\n",
        "        random_tensor += torch.rand([x.shape[0], 1, 1, 1], dtype=torch.float, device=x.device)\n",
        "        random_tensor.requires_grad_(False)\n",
        "        return x / self.ratio * random_tensor.floor()"
      ],
      "metadata": {
        "id": "DnAR1jNCbMTW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MBConv(nn.Module):\n",
        "    def __init__(self, in_, out_, expand=1,\n",
        "                  stride=1, \n",
        "                 se_ratio=0.1, dc_ratio=0.2):\n",
        "        super().__init__()\n",
        "        mid_ = in_ * expand\n",
        "        self.expand_conv = conv_bn_act(in_, mid_, kernel_size=1, bias=False) if expand != 1 else nn.Identity()\n",
        "\n",
        "        self.depth_wise_conv = conv_bn_act(mid_, mid_,\n",
        "                                           kernel_size=3, stride=stride,\n",
        "                                           groups=mid_, bias=False)\n",
        "\n",
        "        self.se = SEModule(mid_, int(in_ * se_ratio)) if se_ratio > 0 else nn.Identity()\n",
        "\n",
        "        self.project_conv = nn.Sequential(\n",
        "            SamePadConv2d(mid_, out_, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_, 1e-3, 0.01)\n",
        "        )\n",
        "\n",
        "        \n",
        "        self.dropconnect = nn.Identity()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        expand = self.expand_conv(inputs)\n",
        "        x = self.depth_wise_conv(expand)\n",
        "        x = self.se(x)\n",
        "        x = self.project_conv(x)\n",
        "        if self.skip:\n",
        "            x = self.dropconnect(x)\n",
        "            x = x + inputs\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "jE5q5qnXa1KK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from SEblock import SE_block\n",
        "from SE_Ibasic import SE_IBasicBlock\n",
        "from IBasic_Block import IBasic_Block"
      ],
      "metadata": {
        "id": "_xdy_BihyxAP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResSaNet50(nn.Module):\n",
        "  def __init__(self, dim_conv_1=64, \n",
        "               dim_stage_1=64,  \n",
        "               dim_stage_2=128,\n",
        "               dim_stage_3=256, \n",
        "               dim_stage_4=512, \n",
        "               dim_FC=512, num_classes=num_classes\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(3, dim_conv_1, kernel_size=1, stride=2, padding=3))\n",
        "    for i in range(3):\n",
        "      layers.append(nn.Conv2d(dim_conv_1, dim_conv_1, kernel_size=3, padding=1))\n",
        "    layers.append(nn.Conv2d(dim_conv_1, dim_stage_1, kernel_size=2))\n",
        "    for i in range(3):\n",
        "      layers.append(IBasic_Block(dim_stage_1, dim_stage_1))\n",
        "    layers.append(nn.Conv2d(dim_stage_1, dim_stage_2, kernel_size=2))\n",
        "    for i in range(4):\n",
        "      layers.append(SE_IBasicBlock(dim_stage_2, dim_stage_2))\n",
        "    layers.append(nn.Conv2d(dim_stage_2, dim_stage_3, kernel_size=2))\n",
        "    for i in range(14):\n",
        "      layers.append(SE_IBasicBlock(dim_stage_3, dim_stage_3))\n",
        "    layers.append(nn.Conv2d(dim_stage_3, dim_stage_4, kernel_size=2))\n",
        "    # for i in range(3):\n",
        "    #   layers.append(IBasic_Transformer(dim_in_stage_4, dim_out_stage_4))\n",
        "    # layers.append(nn.Linear(dim_in_FC, num_classes))\n",
        "\n",
        "    self.main = nn.Sequential(*layers)\n",
        "\n",
        "    k=1\n",
        "    self.MBConv = MBConv(dim_stage_4, dim_stage_4)\n",
        "\n",
        "    self.IBSA = IBSA_Block(dim_stage_4, dim_stage_4)\n",
        "    self.conv = nn.Conv2d(dim_stage_4, dim_FC, kernel_size=1)\n",
        "    self.fc = nn.Linear(dim_FC, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.main(x)\n",
        "    output = self.IBSA(output)\n",
        "    output += self.MBConv(output)\n",
        "    output = self.fc(self.conv(output))\n",
        "    return output"
      ],
      "metadata": {
        "id": "Ih2o0UugSI3z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResSaNet50().cuda()\n",
        "print_network(model, 'ResSaNet50')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar5VLsPXSCxh",
        "outputId": "27b63b58-74c4-4786-d273-0829a7bffeae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "model name ResSaNet50\n",
            "ResSaNet50(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2), padding=(3, 3))\n",
            "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "    (5): IBasic_Block(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (6): IBasic_Block(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (7): IBasic_Block(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (8): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
            "    (9): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (10): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (11): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (12): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (13): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "    (14): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (15): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (16): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (17): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (18): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (19): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (20): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (21): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (22): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (23): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (24): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (25): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (26): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (27): SE_IBasicBlock(\n",
            "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (28): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "  )\n",
            "  (MBConv): MBConv(\n",
            "    (expand_conv): Identity()\n",
            "    (depth_wise_conv): Sequential(\n",
            "      (0): SamePadConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), groups=512, bias=False)\n",
            "      (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Swish()\n",
            "    )\n",
            "    (se): SEModule(\n",
            "      (se): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=1)\n",
            "        (1): Conv2d(512, 51, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): Swish()\n",
            "        (3): Conv2d(51, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (project_conv): Sequential(\n",
            "      (0): SamePadConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (dropconnect): Identity()\n",
            "  )\n",
            "  (IBSA): IBSA_Block(\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (mhsa): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (prelu): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1087, bias=True)\n",
            ")\n",
            "The number of parameters: 23304310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class ArcFaceloss(nn.Module):\n",
        "\n",
        "    def __init__(self, s=45.0, m=0.1, weight = None):\n",
        "        super(ArcFaceloss, self).__init__()\n",
        "      \n",
        "        self.weight = weight\n",
        "        self.s = s\n",
        "        self.cosm = math.cos(m)\n",
        "        self.sinm = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "    \n",
        "    def forward(self, input, labels):\n",
        "        \n",
        "        cost = F.normalize(input)\n",
        "        sint = torch.sqrt(1.0 - torch.square(cost))\n",
        "        cosmt = self.s * (self.cosm * cost - self.sinm * sint)\n",
        "        k = torch.where(cost > self.th, cosmt, self.s * (cost - self.mm))\n",
        "        \n",
        "        label = torch.zeros_like(cost)\n",
        "        label.scatter_(1,labels.view(-1,1).long(),1)\n",
        "        output = (1 - label) * self.s * cost + label * k\n",
        "        \n",
        "        cross_entropy = nn.CrossEntropyLoss()\n",
        "        output = cross_entropy(output, labels)\n",
        "        # print(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "2Q6EFj-fSJUb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch import nn, optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import datetime\n",
        "\n",
        "model = ResSaNet50().cuda()\n",
        "\n",
        "criterion = ArcFaceloss().cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum =0.9, weight_decay=5e-4)\n",
        "\n",
        "Epochs = 30\n",
        "\n",
        "loss = []\n",
        "\n",
        "print('Start training ...')\n",
        "start_time = time.time()\n",
        "for epoch in range(1, Epochs+1):\n",
        "  model.train()\n",
        "\n",
        "  loss_acc = 0 \n",
        "  for i, data in enumerate(data_loader, 0):\n",
        "    images, labels = data\n",
        "    images, labels = images.float().cuda(), labels.cuda()\n",
        "    images = image_to_rgb(images)\n",
        "    labels = labels.type(torch.LongTensor).cuda()\n",
        "    labels = labels.squeeze(-1)\n",
        "    # print(images.size())\n",
        "    # print(labels.size())\n",
        "    logits = model(images)\n",
        "    # print(logits.size())\n",
        "    loss = criterion(logits, labels)\n",
        "    loss_acc += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  loss_acc /= Epochs\n",
        "  et = time.time() - start_time\n",
        "  et = str(datetime.timedelta(seconds=et))[:-7]\n",
        "  log = \"Elapsed [{}], Iteration [{}/{}]\".format(et, epoch, Epochs)\n",
        "  log += ', Loss = %.8f'%(loss_acc)\n",
        "  print(log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "idW2MU4CSMW_",
        "outputId": "32580f56-8fab-4374-a24a-ca7c734fb722"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b63d9c955266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# print(images.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# print(labels.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# print(logits.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-8f70b06929de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIBSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMBConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1dc69788ecee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmhsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'key' and 'value'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = FaceMaskData('test', config)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test,\n",
        "                              batch_size=config['batch_size'],\n",
        "                              shuffle=True, \n",
        "                              num_workers=config['num_workers'])\n",
        "def test_on_resnet(model, test_loader):\n",
        "    \n",
        "    ## -- ! code required  \n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            images, labels = data\n",
        "\n",
        "            images, labels = images.float().cuda(), labels.cuda()\n",
        "            images = image_to_rgb(images)\n",
        "            labels = labels.type(torch.LongTensor).cuda()\n",
        "            labels = labels.squeeze(-1)\n",
        "        \n",
        "            logits = model(images)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total += labels.size(0)\n",
        "            num_correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * num_correct / total         \n",
        "    return acc\n",
        "\n",
        "acc = test_on_resnet(model, test_loader)\n",
        "print('Accuracy of the network on the 10000 test images: %2f %%' % (acc))"
      ],
      "metadata": {
        "id": "AWmY_7_OSRJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
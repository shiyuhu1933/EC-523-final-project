{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSaNet50(nn.Module):\n",
    "  def __init__(self, dim_conv_1=64, \n",
    "               dim_stage_1=64,  \n",
    "               dim_stage_2=128,\n",
    "               dim_stage_3=256, \n",
    "               dim_stage_4=512, \n",
    "               dim_FC=512, num_classes=num_classes\n",
    "               ):\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(3, dim_conv_1, kernel_size=1, kernel_size=7, stride=2, padding=3))\n",
    "    for i in range(3):\n",
    "      layers.append(nn.Conv2d(dim_conv_1, dim_conv_1, kernel_size=3, padding=1))\n",
    "    layers.append(nn.Conv2d(dim_conv_1, dim_stage_1, kernel_size=2))\n",
    "    for i in range(3):\n",
    "      layers.append(IBasic_Block(dim_stage_1, dim_stage_1))\n",
    "    layers.append(nn.Conv2d(dim_stage_1, dim_stage_2, kernel_size=2))\n",
    "    for i in range(4):\n",
    "      layers.append(SE_IBasicBlock(dim_stage_2, dim_stage_2))\n",
    "    layers.append(nn.Conv2d(dim_stage_2, dim_stage_3, kernel_size=2))\n",
    "    for i in range(14):\n",
    "      layers.append(SE_IBasicBlock(dim_stage_3, dim_stage_3))\n",
    "    layers.append(nn.Conv2d(dim_stage_3, dim_stage_4, kernel_size=2))\n",
    "    # for i in range(3):\n",
    "    #   layers.append(IBasic_Transformer(dim_in_stage_4, dim_out_stage_4))\n",
    "    # layers.append(nn.Linear(dim_in_FC, num_classes))\n",
    "\n",
    "    self.main = nn.Sequential(*layers)\n",
    "\n",
    "    k=1\n",
    "    self.MBConv = nn.Sequential(\n",
    "      nn.Conv2d(dim_stage_4, dim_stage_4, kernel_size=1, stride=1, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.BatchNorm2d(dim_stage_4, affine=True, track_running_stats=True),\n",
    "      nn.Conv2d(dim_stage_4, k*dim_stage_4, kernel_size=3, stride=1, padding=1, groups=dim_stage_4),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.BatchNorm2d(dim_stage_4, affine=True, track_running_stats=True),\n",
    "     # SE_block(dim_stage_4, dim_stage_4, stride=1, padding=1, enable=True),\n",
    "      nn.Conv2d(dim_stage_4, dim_stage_4, kernel_size=1, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(dim_stage_4, affine=True, track_running_stats=True))\n",
    "\n",
    "    self.IBSA = IBSA_Block(dim_stage_4, dim_stage_4)\n",
    "    self.conv = nn.Conv2d(dim_stage_4, dim_FC, kernel_size=1)\n",
    "    self.fc = nn.Linear(dim_FC, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = self.main(x)\n",
    "    output = self.IBSA(output)\n",
    "    output += self.MBConv(output)\n",
    "    output = self.fc(self.conv(output))\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    conv3x3 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    return conv3x3\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    conv1x1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "    return conv1x1\n",
    "\n",
    "class SE_block(nn.Module):\n",
    "    def __init__(self, inplanes):\n",
    "        super(SE_block, self).__init__()\n",
    "        self.se_conv1 = conv1x1(inplanes, inplanes//16)\n",
    "        self.se_conv2 = conv1x1(inplanes//16, inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.avgpool(x)\n",
    "        out = self.se_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.se_conv2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return x * out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "copy from: https://github.com/leaderj1001/BottleneckTransformers\n",
    "author: Myeongjun Kim\n",
    "'''\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "\n",
    "    def __init__(self, n_dims, width=4, height=4, heads=4):\n",
    "        super(MHSA, self).__init__()\n",
    "        self.heads = heads\n",
    "\n",
    "        self.query = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n",
    "        self.key = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n",
    "        self.value = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n",
    "\n",
    "        self.rel_h = nn.Parameter(torch.randn([1, heads, n_dims // heads, 1, height]), requires_grad=True)\n",
    "        self.rel_w = nn.Parameter(torch.randn([1, heads, n_dims // heads, width, 1]), requires_grad=True)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_batch, C, width, height = x.size()\n",
    "        q = self.query(x).view(n_batch, self.heads, C // self.heads, -1)\n",
    "        k = self.key(x).view(n_batch, self.heads, C // self.heads, -1)\n",
    "        v = self.value(x).view(n_batch, self.heads, C // self.heads, -1)\n",
    "\n",
    "        content_content = torch.matmul(q.permute(0, 1, 3, 2), k)\n",
    "\n",
    "        content_position = (self.rel_h + self.rel_w).view(1, self.heads, C // self.heads, -1).permute(0, 1, 3, 2)\n",
    "        content_position = torch.matmul(content_position, q)\n",
    "\n",
    "        energy = content_content + content_position\n",
    "        attention = self.softmax(energy)\n",
    "\n",
    "        out = torch.matmul(v, attention.permute(0, 1, 3, 2))\n",
    "        out = out.view(n_batch, C, width, height)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''modified from BasicBlock in iResNet.ipynb'''\n",
    "\n",
    "\n",
    "class IBT(nn.Module):\n",
    "    exp_block = 1\n",
    "\n",
    "    def __init__(self, inplanes, outplanes, stride=1, downsample=None, nm_layer=None, s_block=False, e_block=False, exd_bn0=False):\n",
    "        super(IBT, self).__init__()\n",
    "\n",
    "        if nm_layer is None:\n",
    "            nm_layer = nn.BatchNorm2d\n",
    "        if not s_block and not exd_bn0:\n",
    "            self.bn0 = nm_layer(outplanes)\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, outplanes, stride)\n",
    "        self.bn1 = nm_layer(outplanes)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.mhsa = MHSA(outplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv1x1(outplanes, outplanes)\n",
    "\n",
    "        self.dw_conv3x3 = nn.Sequential(\n",
    "            nn.Conv2d(outplanes, outplanes, 3, padding=1, groups=outplanes, bias=False),\n",
    "            nn.BatchNorm2d(outplanes))\n",
    "        self.se = SE_block(outplanes)\n",
    "\n",
    "        if s_block:\n",
    "            self.bn2 = nm_layer(outplanes)\n",
    "\n",
    "        if e_block:\n",
    "            self.bn2 = nm_layer(outplanes)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        self.s_block = s_block\n",
    "        self.e_block = e_block\n",
    "        self.exd_bn0 = exd_bn0\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        id_ibsa = x\n",
    "\n",
    "        if self.s_block:\n",
    "            out = self.conv1(x)\n",
    "        elif self.exd_bn0:\n",
    "            out = self.relu(x)\n",
    "            out = self.conv1(out)\n",
    "        else:\n",
    "            out = self.bn0(x)\n",
    "            out = self.relu(out)\n",
    "            out = self.conv1(out)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.mhsa(out)\n",
    "\n",
    "        id_ibsa = self.conv1(id_ibsa)\n",
    "\n",
    "        out = out + id_ibsa\n",
    "\n",
    "        identity = out\n",
    "\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.dw_conv3x3(out)\n",
    "\n",
    "        out = self.se(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.s_block:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "\n",
    "        if self.e_block:\n",
    "            out = self.bn2(out)\n",
    "            out = self.prelu(out)\n",
    "\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
